{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Deep Q-Network (DDQN)\n",
    "这是DQN原本的目标：\n",
    "$$ r + \\gamma \\max_{a'} Q(s',a') $$\n",
    "但是上述目标被证实存在overestimation问题，于是我们引入了DDQN，首先把原目标的公式变一个样子：\n",
    "$$ r + \\gamma Q(s', \\arg\\max_{a'} Q(s',a')) $$\n",
    "这个公式相当于先找出最好的$a'$，然后把这个$a'$代入到$Q$里，其实就是等于求了max。因为$\\max_{x}{f(X)} = f(\\arg\\max_{x} f(X))$<p>\n",
    "然后，再变一下：\n",
    "$$ r + \\gamma Q(s', \\arg\\max_{a'} Q'(s',a')) $$\n",
    "这里用了两个value function，一个是$Q$，一个是$Q'$，两者使用不同的参数，但他们的功能一样，当然也可以反过来：\n",
    "$$ r + \\gamma Q'(s', \\arg\\max_{a'} Q(s',a')) $$\n",
    "两个Q一个用于找最好的action，另一个用于计算value的值，这样就可以避免overestimation的问题了，至于这个overestimation是为什么，或者为什么DDQN就能把它解决，请直接看论文。<p>\n",
    "实际的代码实现中和DQN是一样的，只不过$Q$和$Q'$谁在里谁在外是随机的，但每次更新参数的时候只更新两者之一。<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
